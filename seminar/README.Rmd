---
title: "Seminarska naloga 1 (Umetna Inteligence 2021-2022)"
author: "Bartolomej Kozorog (63200152)"
date: "December 5, 2021"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
    highlight: tango
    df_print: kable
  md_document:
    variant: markdown_github
    toc: yes
  html_document:
    toc: yes
    df_print: paged
    number_sections: true
    toc_depth: 3
---

Cilj seminarske naloge je uporabiti metode strojnega učenja za gradnjo modelov za napovedovanje
porabe električne energije (regresijski problem) in namembnosti stavbe (klasifikacijski problem),
ustrezno ovrednotiti modele in jasno predstaviti dobljene rezultate.

## Knjiznice in orodja

Vecina uporabljenih knjiznic je ze privzeto namescenih. Potrebno pa bo namestiti tudi nekaj zunanjih knjicnic, kot sta `ggplot2` in `ggcorrplot` (za risanje grafov).

Vecina pomoznih metod se nahaja v zunanji R skripti `common.R`.

```{R}
library(lubridate) # delo z datumi
library(stringr) # delo z znakovnimi nizi
library(ggplot2)
library(ggcorrplot)
library(rpart)
library(rpart.plot)
library(CORElearn) # za ucenje
library(nnet)
library(randomForest)
library(ipred) # bagging
library(adabag) # boosting

source("./common.R") # pomozne metode

set.seed(0) # nastavimo random seed
```

## Vizualizacija podatkov

### Uvoz podatkov

Najprej uvozimo in na kratko preglejmo podatke. 

Opazimo, da imamo 3 atribute tipa "character": `datum`, `regija` in `namembnost`. Atributa `regija` in `namembnost` (z indeksi `2` in `4`) imata le majhno stevilo vrednosti, zato jih bomo faktorizirali. Datum bomo pa kasneje preuredili v bolj smiselno obliko.
```{R}
train <- read.table("trainset.txt", header=T, sep=",")
test <- read.table("testset.txt", header=T, sep=",")

train <- Factorize(train)
test <- Factorize(test)

allData <- rbind(test, train)
```

### Izris grafov

#### Porazdelitvene vrednosti

Vizualizirajmo porazdelitvene vrednosti posameznih atributov, da dobimo boljsi vpogled v vsak atribut posebej.
```{R}
pie(table(allData$namembnost), xlab="Namembnost")
hist(allData$povrsina, xlab="Povrsina (m^2)", main="Histogram povrsine stavb")
hist(allData$poraba, xlab="Poraba (kWh)", main="Histogram porabe stavb")
hist(allData$leto_izgradnje, xlab="Leto izgradnje", main="Histogram leta izgradnje stavb")
hist(allData$temp_zraka, xlab="Temperatura zraka (°C)", main="Histogram temperature zraka")
hist(allData$temp_rosisca, xlab="Temperatura rosisca (°C)", main="Histogram temperature rosisca")
hist(allData$oblacnost, xlab="Oblacnost", main="Histogram stopnje pokritosti neba z oblaki")
hist(allData$padavine, xlab="Padavine (mm)", main="Histogram kolicine padavin")
hist(allData$pritisk, xlab="Pritisk (mbar)", main="Histogram zracnega pritiska")
hist(allData$smer_vetra, xlab="Smer vetra (°)", main="Histogram smeri vetra")
hist(allData$hitrost_vetra, xlab="Hitrost vetra (m/s)", main="Histogram hitrosti vetra")
```

#### Namembnost in regija


#### Namembnost stavb glede na regijo

*Ugotovitve:*
- priblizno polovica stavb sluzi izobrazevalnemu namenu
- stavb z zahodno lego je malo vec kot stavb z zahodno lego
- stavbe z vzhodno lego imajo za skoraj 13% vec stavb za izobrazevalne namene kot stavbe z zahodno lego
```{R}
CalcEducationalPercentage <- function(regija)
{
  filtered <- allData[allData$regija == regija,]
  nrow(filtered[filtered$namembnost == "izobrazevalna",]) / nrow(filtered)
}
p <- ggplot(allData, aes(regija))
p + geom_bar(aes(fill=namembnost), width = 0.5)

paste("Odstotek izobrazevalnih stavb z vzhodno regijo", CalcEducationalPercentage("vzhodna"))
paste("Odstotek izobrazevalnih stavb z zahodno regijo", CalcEducationalPercentage("zahodna"))
```

#### Soodvisnost atributov

Pri nadalnji predikciji nam bo koristilo tudi nekaj intuicije o soodvisnosti med doloceni atributi. 

Ze samo po sebi je logicno, da bodo nekateri atributi (npr. povrsina train <-> poraba energije) v vecji medsebojni odvisnosti, kot nekateri drugi atributi (npr. smer vetra <-> poraba energije);

Naso hipotezo lahko dodatno potrdimo z nekaj grafi, kjer prikazemo korelacijo med izbranimi pari atributov.

Pri porabi elektricne energije v odvisnosti z povrsino train vidimo, da obstaja jasen pozitiven trend. 
```{R}
x <- train$povrsina
y <- train$poraba
plot(x, y, col="lightblue")
abline(lm(y ~ x), col = "red", lwd = 3)
```

Medtem ko pri grafu porabe energije v odvisnosti od smeri vetra jasne korelacije ni.
```{R}
x <- train$smer_vetra
y <- train$poraba
plot(x, y, col="lightblue")
abline(lm(y ~ x), col = "red", lwd = 3)
```

Najboljse bi bilo primerjati vse (numericne) atribute z vsemi drugimi atributi, ter prikazati medsebojne odvisnosti, tako bi pridobili visoko nivojski pogled na odvisnosti med atributi.

Za to vrstno vizualizacijo bomo uporabili dve zunanji knjiznici `ggplot2` in `ggcorrplot`, ki jih moramo prenesti in namestiti.

Ta graf nam izpise korelacijsko matriko, iz katere lahko razberemo korelacije med vsemi numericni atributi. Opazimo, da sta v najvecji medsebojni korelaciji res atributa `poraba` in `povrsina`.
```{R}
data(train, package="mosaicData")

# izberemo samo numericne atribute
df <- dplyr::select_if(train, is.numeric)

# izracunamo korelacije z metodo cor
r <- cor(df, use="complete.obs")
round(r,2)

ggcorrplot(r,
           hc.order=T, # uredi po korelaciji
           type="lower") # prikazi samo v spodnjem trikotniku
```


## Priprava atributov

### Pomozne metode

Sedaj bomo poskusali izboljsati kvaliteto posameznih atributov. Pri tem bomo uporabili nekaj pomoznih metod za evaluacijo.

Metoda `evalClassFeatures` bo evaluirala podatke z dano formulo z vsemi definiranimi ocenami za klasifikacijske probleme. Prav tako bo metoda `evalRegrFeatures` evaluirala atribute z definiranimi ocenami za regresijske probleme.

```{R}

evalFeatures <- function (formula, data, estimators)
{
  for (estimator in estimators) {
    score = attrEval(formula, data, estimator);
    
    cat(paste(estimator, "\n"))
    print(sort(score, decreasing=T))
    cat("\n\n")
  }
}

evalClassFeatures <- function (formula, data)
{
  shortSighted <- list("InfGain", "GainRatio", "Gini", "MDL")
  nonShortSighted <- list("Relief", "ReliefFequalK", "ReliefFexpRank")
  estimators <- c(shortSighted, nonShortSighted)
  evalFeatures(formula, data, estimators)
}

evalRegrFeatures <- function (formula, data)
{
  estimators <- list("MSEofMean", "RReliefFexpRank")
  evalFeatures(formula, data, estimators)
}
```


### Izboljsava mnozice atributov

Poskusimo izboljsati prvotno podatkovno mnozico z dodajanjem / odstranjevanjem atributov. Namen je najti cim manjso mnozico atributov ki maksimizira kvaliteto modela.
```{R}
# atributi za klasifikacijski problem
classSetBase <- list(train=train, test=test)
classSetExt <- list(train=train, test=test)

ExtendClassSet <- function (set)
{
  set$oblacnost <- log1p(set$oblacnost)
  set$poraba <- log1p(set$poraba)
  set$povrsina <- log1p(set$povrsina)
  set$datum <- NULL
  set
}

classSetExt$train <- ExtendClassSet(classSetExt$train)
classSetExt$test <- ExtendClassSet(classSetExt$test)

# atributi za regresijski problem
regSetBase <- list(train=train, test=test)
regSetExt <- list(train=train, test=test)

ExtendRegSet <- function (set)
{
  set$letni_cas <- as.factor(ToSeason(set$datum))
  set$mesec <- as.factor(ToMonth(set$datum))
  set$zima <- as.factor(IsWinter(set$datum))
  set$vikend <- as.factor(IsWeekend(set$datum))
  set$pritisk <- log1p(set$pritisk)
  set$hitrost_vetra <- log1p(set$hitrost_vetra)
  
  set$datum <- NULL
  set$stavba <- NULL
  set$temp_rosisca <- NULL
  set$padavine <- NULL
  set$smer_vetra <- NULL
  
  set$namembnost <- NULL
  set$temp_zraka <- NULL
  
  set$oblacnost <- log1p(set$oblacnost)
  set$poraba <- log1p(set$poraba)
  set$povrsina <- log1p(set$povrsina)
  
  set
}

regSetExt$train <- ExtendRegSet(regSetExt$train)
regSetExt$test <- ExtendRegSet(regSetExt$test)
```

### Evalvacija atributov

Poglejmo si vse ocene za prvotni mnozici atributov:

```{R}
evalClassFeatures(namembnost ~ ., classSetBase$train)
```

```{R}
evalRegrFeatures(poraba ~ ., regSetBase$train)
```

Ponovno evaluiramo atribute za popravljeni mnozici atributov:
```{R}
evalClassFeatures(namembnost ~ ., classSetExt$train)
```

```{R}
evalRegrFeatures(poraba ~ ., regSetExt$train)
```


## Klasifikacija

### Vecinski klasifikator

Vecinski klasifikator uvrsti vsak primer v razred ki se najveckrat pojavi. 
Ta klasifikator bo predstavljal spodnjo mejo kvalitete ucnih modelov.
```{R}
# najveckrat se ponovi "izobrazevalna" namembnost
sum(test$namembnost == "izobrazevalna") / length(test$namembnost)
```

### Odlocitveno drevo

```{R}
# osnovna mnozica atributov
dtBase <- rpart(namembnost ~ pritisk, data=classSetBase$train)
EvaluateClassModel(dtBase, classSetBase$train, classSetBase$test)

# popravljena mnozica atributov
dtExt <- rpart(namembnost ~ ., data=classSetExt$train)
EvaluateClassModel(dtExt, classSetExt$train, classSetExt$test)
```

### Odlocitveno drevo z rezanjem

Izberemo vrednost parametra cp, ki ustreza minimalni napaki internega presnega preverjanja.
```{R}
dtBase <- rpart(namembnost ~ ., data=classSetBase$train, cp=0)
cpTab <- printcp(dtBase)
row <- which.min(cpTab[,"xerror"])
th <- mean(c(cpTab[row, "CP"], cpTab[row-1, "CP"]))
dtBase <- prune(dtBase, cp=th)
EvaluateClassModel(dtBase, classSetBase$train, classSetBase$test)

dtExt <- rpart(namembnost ~ ., data=classSetExt$train, cp=0)
cpTab <- printcp(dtExt)
row <- which.min(cpTab[,"xerror"])
th <- mean(c(cpTab[row, "CP"], cpTab[row-1, "CP"]))
dtExt <- prune(dtExt, cp=th)
EvaluateClassModel(dtExt, classSetExt$train, classSetExt$test)
```

### Naivni Bayes

```{r}
nbBase <- CoreModel(namembnost ~ ., data=classSetBase$train, model="bayes")
EvaluateClassModel(nbBase, classSetBase$train, classSetBase$test)

nbExt <- CoreModel(namembnost ~ ., data=classSetExt$train, model="bayes")
EvaluateClassModel(nbExt, classSetExt$train, classSetExt$test)
```

### K-bliznjih sosedov

```{R}
knnBase <- CoreModel(namembnost ~ ., data=classSetBase$train, model="knn", kInNN=5)
EvaluateClassModel(knnBase, classSetBase$train, classSetBase$test)

knnExt <- CoreModel(namembnost ~ ., data=classSetExt$train, model="knn", kInNN=5)
EvaluateClassModel(knnExt, classSetExt$train, classSetExt$test)
```


### Nakljucni gozd

```{R}
rfBase <- randomForest(namembnost ~ ., data=classSetBase$train)
EvaluateClassModel(rfBase, classSetBase$train, classSetBase$test)

rfExt <- randomForest(namembnost ~ ., data=classSetExt$train)
EvaluateClassModel(rfExt, classSetExt$train, classSetExt$test)
```

## Regresija


### Trivialni model
Trivialni model vedno vraca povprecno vrednost ciljne spremenljivke, glede na vse ucne primere.
Ta model bo predstavljal spodnjo mejo kvalitete ucnih modelov.
```{R}
meanValue <- mean(regSetBase$train$poraba)
predicted <- rep(meanValue, nrow(regSetBase$test))
observed <- regSetBase$test$poraba

EvaluateTrivialRegModel(observed, predicted)
```

### Linearna regresija

```{R}
# osnovna mnozica atributov
lmBase <- lm(poraba ~ povrsina + leto_izgradnje, regSetBase$train)
EvaluateRegBaseModel(lmBase, regSetBase$train, regSetBase$test)

# popravljena mnozica atributov
lmExt <- lm(poraba ~ ., regSetExt$train)
EvaluateRegExtModel(lmExt, regSetExt$train, regSetExt$test)
```

#### Regresijsko drevo

```{R}
# osnovna mnozica atributov
baseModel <- rpart(poraba ~ ., data=regSetBase$train)
EvaluateRegBaseModel(baseModel, regSetBase$train, regSetBase$test)

# popravljena mnozica atributov
extModel <- rpart(poraba ~ ., data=regSetExt$train)
EvaluateRegExtModel(extModel, regSetExt$train, regSetExt$test)
```


### Nakljucni gozd

```{R}
# osnovna mnozica atributov
baseModel <- randomForest(poraba ~ ., data=regSetBase$train)
EvaluateRegBaseModel(baseModel, regSetBase$train, regSetBase$test)

# popravljena mnozica atributov
extModel <- randomForest(poraba ~ ., data=regSetExt$train)
EvaluateRegExtModel(extModel, regSetExt$train, regSetExt$test)
```


### Nevronske mreze

```{R}
# osnovna mnozica atributov
baseModel <- nnet(poraba ~ ., regSetBase$train, size=5, decay=0.001, maxit=10000, linout=T)
EvaluateRegBaseModel(baseModel, regSetBase$train, regSetBase$test)

# popravljena mnozica atributov
extModel <- nnet(poraba ~ ., regSetExt$train, size=5, decay=0.001, maxit=10000, linout=T)
EvaluateRegExtModel(extModel, regSetExt$train, regSetExt$test)
```


## Izboljsava klasifikacijskih modelov

### Metoda ovojnice

Izboljsava klasifikacijskega modela z izbiro optimalne podmnozice atributov, ki minimizira doloceno oceno.
```{R}
runWrapper(namembnost ~ ., classSetBase$train)

dtBase <- rpart(namembnost ~ povrsina + leto_izgradnje + stavba + datum + regija + temp_zraka + temp_rosisca + oblacnost, data=classSetBase$train)
EvaluateClassModel(dtBase, classSetBase$train, classSetBase$test)
```

### Glasovanje

Zgradimo modele z osnovno in popravljeno mnozico atributov:
```{R}
dtBase <- rpart(namembnost ~ pritisk, data=classSetBase$train)
knnBase <- CoreModel(namembnost ~ ., data=classSetBase$train, model="knn", kInNN=5)
rfBase <- randomForest(namembnost ~ ., data=classSetBase$train)

dtExt <- rpart(namembnost ~ pritisk, data=classSetExt$train)
knnExt <- CoreModel(namembnost ~ ., data=classSetExt$train, model="knn", kInNN=5)
rfExt <- randomForest(namembnost ~ ., data=classSetExt$train)
```

Glasovanje z osnovno mnozico atributov:
```{R}
predDtBase <- predict(dtBase, classSetBase$test, type="class")
predKnnBase <- predict(knnBase, classSetBase$test, type="class")
predRfBase <- predict(rfBase, classSetBase$test, type="class")

modelsDf <- data.frame(
  predDtBase,
  predKnnBase,
  predRfBase
)

runVoting(modelsDf, classSetBase$test$namembnost)
```

Glasovanje z popravljeno mnozico atributov:
```{R}
predDtExt <- predict(dtExt, classSetExt$test, type="class")
predKnnExt <- predict(knnExt, classSetExt$test, type="class")
predRfExt <- predict(rfExt, classSetExt$test, type="class")

modelsDf <- data.frame(
  predDtExt,
  predKnnExt,
  predRfExt
)

runVoting(modelsDf, classSetExt$test$namembnost)
```


### Utezeno glasovanje

Glasovanje z osnovno mnozico atributov:
```{R}
predDtBase <- predict(dtBase, classSetBase$test, type="prob")
predKnnBase <- predict(knnBase, classSetBase$test, type="prob")
predRfBase <- predict(rfBase, classSetBase$test, type="prob")
runWeightedVoting(predDtBase + predKnnBase + predRfBase, classSetBase$test$namembnost)
```

Glasovanje z popravljeno mnozico atributov:
```{R}
predDtExt <- predict(dtExt, classSetExt$test, type="prob")
predKnnExt <- predict(knnExt, classSetExt$test, type="prob")
predRfExt <- predict(rfExt, classSetExt$test, type="prob")
runWeightedVoting(predDtExt + predKnnExt + predRfExt, classSetExt$test$namembnost)
```

### Bagging

Bagging z osnovno mnozico atributov:
```{R}
bag <- bagging(namembnost ~ ., classSetBase$train, nbagg=30)
predictions <- predict(bag, classSetBase$test)
ca <- CA(classSetBase$test$namembnost, predictions$class)
print(paste("Classification accuracy:", ca))
```

Bagging z popravljeno mnozico atributov:
```{R}
bag <- bagging(namembnost ~ ., classSetExt$train, nbagg=30)
predictions <- predict(bag, classSetExt$test)
ca <- CA(classSetExt$test$namembnost, predictions$class)
print(paste("Classification accuracy:", ca))
```

### Boosting

Boosting z osnovno mnozico atributov:
```{R}
bm <- boosting(namembnost ~ ., classSetBase$train, mfinal=100)
predictions <- predict(bm, classSetBase$test)
ca <- CA(classSetBase$test$namembnost, predictions$class)
print(paste("Classification accuracy:", ca))
```

Boosting z popravljeno mnozico atributov:
```{R}
bm <- boosting(namembnost ~ ., classSetExt$train, mfinal=100)
predictions <- predict(bm, classSetExt$test)
ca <- CA(classSetExt$test$namembnost, predictions$class)
print(paste("Classification accuracy:", ca))
```

## Primerjava po regijah


### Priprava podatkov

Pripravimo podatke, tako da ucno in testno mnozico razbijemo na dve podmnozici:
- mnozica ki vsebuje samo primere z vzhodno regijo
- mnozica ki vsebuje samo primere z zahodno regijo

#### Podatki za klasifikacijo
```{R}
selTrain <- classSetExt$train$regija == "vzhodna"
selTest <- classSetExt$test$regija == "vzhodna"

classVzhodnaTrain <- classSetExt$train[selTrain,]
classVzhodnaTest <- classSetExt$test[selTest,]
classVzhodnaTrain$regija <- NULL
classVzhodnaTest$regija <- NULL

classZahodnaTrain <- classSetExt$train[!selTrain,]
classZahodnaTest <- classSetExt$test[!selTest,]
classZahodnaTrain$regija <- NULL
classZahodnaTest$regija <- NULL
```

#### Podatki za regresijo

```{r}
selTrain <- regSetExt$train$regija == "vzhodna"
selTest <- regSetExt$test$regija == "vzhodna"

regVzhodnaTrain <- regSetExt$train[selTrain,]
regVzhodnaTest <- regSetExt$test[selTest,]
regVzhodnaTrain$regija <- NULL
regVzhodnaTest$regija <- NULL

regZahodnaTrain <- regSetExt$train[!selTrain,]
regZahodnaTest <- regSetExt$test[!selTest,]
regZahodnaTrain$regija <- NULL
regZahodnaTest$regija <- NULL
```

### Evalvacija

#### Klasifikacija

Zgradimo nekaj klasifikacijskih modelov, ki se ucijo iz posamezne podmnozice, ter vsakega posebej se ocenimo glede na testne primere iz ustrezne testne mnozice.

```{R}
runClassification(namembnost ~ ., classVzhodnaTrain, classVzhodnaTest)
```

```{R}
runClassification(namembnost ~ ., classZahodnaTrain, classZahodnaTest)
```

#### Regresija

Zgradimo nekaj regresijskih modelov, ki se ucijo iz posamezne podmnozice, ter vsakega posebej se ocenimo glede na testne primere iz ustrezne testne mnozice.

```{R}
runRegression(poraba ~ ., regVzhodnaTrain, regVzhodnaTest)
```

```{R}
runRegression(poraba ~ ., regZahodnaTrain, regZahodnaTest)
```


## Evalvacija po mesecih

```{R}
regData <- ExtendRegSet(allData)
classData <- ExtendClassSet(allData)
classData$mesec <- as.factor(ToMonth(allData$datum))

regDataByMonth = list()
classDataByMonth = list()

for (i in 1:12) 
{
  regDataByMonth[[i]] <- regData[regData$mesec==i,]
  classDataByMonth[[i]] <- classData[classData$mesec==i,]
  classDataByMonth[[i]]$mesec <- NULL
  regDataByMonth[[i]]$mesec <- NULL
  regDataByMonth[[i]]$letni_cas <- NULL
  regDataByMonth[[i]]$zima <- NULL
}

brier <- vector()
ca <- vector()
infGain <- vector()

mae <- vector()
mse <- vector()
rmse <- vector()
rmae <- vector()


for (i in 1:11) 
{
  regTrain <- do.call("rbind", regDataByMonth[1:i])
  regTest <- regDataByMonth[[i + 1]]
  
  classTrain <- do.call("rbind", classDataByMonth[1:i])
  classTest <- classDataByMonth[[i + 1]]

  dt <- rpart(namembnost ~ ., data=classTrain)
  score <- EvaluateClassModel(dt, classTrain, classTest, F)
  brier[i] <- score$brier
  ca[i] <- score$ca
  infGain[i] <- score$infGain
  
  lmExt <- lm(poraba ~ ., regTrain)
  score <- EvaluateRegExtModel(lmExt, regTrain, regTest, F, F)
  mae[i] <- score$mae
  mse[i] <- score$mse
  rmse[i] <- score$rmse
  rmae[i] <- score$rmae
}
```

### Ocene klasifikacije

```{r}
drawClassEvaluationGraph(brier, ca, infGain)
```

### Ocene regresije

```{r}
drawRegrEvaluationGraph(rmse, rmae)
```


## Zakljucek

V tej seminarski nalogi sem zgradil in evaluiral nekaj razlicnih klasifikacijskih in regresijskih modelov.

Pri klasifikaciji je bil najbolj kvaliteten model nakljucnega gozda, najslabsi pa naivni bayesov klasifikator. Medtem ko je bila pri regresiji najboljsa metoda linearne regresija, najslabsa pa metoda nevronskih mrez.

Pri locenem ucenju glede na regije smo opazili, da je klasifikacijska in regresijska napoved obcutno uspesnejsa za primere iz podmnozice podatkov z vzhodno regijo. Eden izmed moznih razlogov za to je verjetno tudi dejstvo, da so stavbe za izobrazevalne namene vecinski razred, ter da imajo stavbe z vzhodno lego imajo za skoraj 13% vec stavb za izobrazevalne namene kot stavbe z zahodno lego.