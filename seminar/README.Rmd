---
output: 
  md_document:
    variant: markdown_github
    toc: true
---

# Seminarska naloga

Cilj seminarske naloge je uporabiti metode strojnega učenja za gradnjo modelov za napovedovanje
porabe električne energije (regresijski problem) in namembnosti stavbe (klasifikacijski problem),
ustrezno ovrednotiti modele in jasno predstaviti dobljene rezultate.

## Knjiznice in orodja

```{R}
library(lubridate) # delo z datumi
library(stringr) # delo z znakovnimi nizi
library(ggplot2)
library(ggcorrplot)
library(rpart)
library(rpart.plot)
library(CORElearn) # za ucenje
library(nnet)
library(randomForest)

source("./common.R") # pomozne metode

set.seed(0) # nastavimo random seed
```

## Vizualizacija podatkov

### Uvoz podatkov

Najprej uvozimo in na kratko preglejmo podatke. 

Opazimo, da imamo 3 atribute tipa "character": `datum`, `regija` in `namembnost`. Atributa `regija` in `namembnost` (z indeksi `2` in `4`) imata le majhno stevilo vrednosti, zato jih bomo faktorizirali. Datum bomo pa kasneje preuredili v bolj smiselno obliko.
```{R}
train <- read.table("trainset.txt", header=T, sep=",")
test <- read.table("testset.txt", header=T, sep=",")

# zmanjsamo mnozici za potrebo razvoja
trainSel <- sample(1:nrow(train), as.integer(nrow(train) * 0.1), replace=T)
testSel <- sample(1:nrow(test), as.integer(nrow(test) * 0.1), replace=T)
train <- train[trainSel,]
test <- test[testSel,]

summary(train)

train <- Factorize(train)
test <- Factorize(test)

summary(train)
```

### Izris grafov

Najprej vizualizirajmo porazdelitvene vrednosti posameznih atributov, da dobimo boljsi vpogled v vsak atribut posebej.
```{R}
pie(table(train$regija), xlab="Regija")
pie(table(train$stavba), xlab="Oznaka stavbe")
pie(table(train$namembnost), xlab="Namembnost")
hist(train$povrsina, xlab="Povrsina (m^2)", main="Histogram povrsine stavb")
hist(train$poraba, xlab="Poraba (kWh)", main="Histogram porabe stavb")
hist(train$leto_izgradnje, xlab="Leto izgradnje", main="Histogram leta izgradnje stavb")
hist(train$temp_zraka, xlab="Temperatura zraka (°C)", main="Histogram temperature zraka")
hist(train$temp_rosisca, xlab="Temperatura rosisca (°C)", main="Histogram temperature rosisca")
hist(train$oblacnost, xlab="Oblacnost", main="Histogram stopnje pokritosti neba z oblaki")
hist(train$oblacnost, xlab="Padavine (mm)", main="Histogram kolicine padavin")
hist(train$oblacnost, xlab="Pritisk (mbar)", main="Histogram zracnega pritiska")
hist(train$smer_vetra, xlab="Smer vetra (°)", main="Histogram smeri vetra")
hist(train$smer_vetra, xlab="Hitrost vetra (m/s)", main="Histogram hitrosti vetra")
```

Pri nadalnji predikciji nam bo koristilo tudi nekaj intuicije o soodvisnosti med doloceni atributi. 

Ze samo po sebi je logicno, da bodo nekateri atributi (npr. povrsina train <-> poraba energije) v vecji medsebojni odvisnosti, kot nekateri drugi atributi (npr. smer vetra <-> poraba energije);

Naso hipotezo lahko dodatno potrdimo z nekaj grafi, kjer prikazemo korelacijo med izbranimi pari atributov.

Zdaj izrisimo nekaj korelacijskih grafov, da potrimo ali pa ovrzemo nase hipoteze. Da bo trend se bolje viden, lahko na graf izrisemo se linearno regresijsko premico.

Pri porabi elektricne energije v odvisnosti z povrsino train vidimo, da obstaja jasen trend.
```{R}
x <- train$povrsina
y <- train$poraba
plot(x, y, col="lightblue")
abline(lm(y ~ x), col = "red", lwd = 3)
```

Medtem ko pri grafu porabe energije v odvisnosti od smeri vetra jasne korelacije ni.
```{R}
x <- train$smer_vetra
y <- train$poraba
plot(x, y, col="lightblue")
abline(lm(y ~ x), col = "red", lwd = 3)
```

Najboljse bi bilo primerjati vse atribute z vsemi drugimi atributi, ter prikazati medsebojne odvisnosti, tako bi pridobili visoko nivojski pogled na odvisnosti med atributi.

Za to vrstno vizualizacijo bomo uporabili dve zunanji knjiznici `ggplot2` in `ggcorrplot`, ki jih moramo prenesti in namestiti.

Ta graf nam izpise korelacijsko matriko, iz katere lahko razberemo korelacije med vsemi numericni atributi. Opazimo, da sta v najvecji medsebojni korelaciji res atributa `poraba` in `povrsina`.
```{R}
data(train, package="mosaicData")

# izberemo samo numericne atribute
df <- dplyr::select_if(train, is.numeric)

# izracunamo korelacije z metodo cor
r <- cor(df, use="complete.obs")
round(r,2)

ggcorrplot(r,
           hc.order=T, # uredi po korelaciji
           type="lower") # prikazi samo v spodnjem trikotniku
```


## Priprava atributov


### Pomozne metode

Sedaj bomo poskusali izboljsati kvaliteto posameznih atributov. Najbolj ociten atribut, ki potrebuje izboljsavo oz. obdelavo je `datum`.

Najprej bomo napisali nekaj pomoznih metod za evaluacijo atributov. 

Metoda `evalClassFeatures` bo evaluirala podatke z dano formulo z vsemi definiranimi ocenami za klasifikacijske probleme. Prav tako bo metoda `evalRegrFeatures` evaluirala atribute z definiranimi ocenami za regresijske probleme.

```{R}

evalFeatures <- function (formula, data, estimators)
{
  for (estimator in estimators) {
    score = attrEval(formula, data, estimator);
    
    cat(paste(estimator, "\n"))
    print(sort(score, decreasing=T))
    cat("\n\n")
  }
}

evalClassFeatures <- function (formula, data)
{
  shortSighted <- list("InfGain", "GainRatio", "Gini", "MDL")
  nonShortSighted <- list("Relief", "ReliefFequalK", "ReliefFexpRank")
  estimators <- c(shortSighted, nonShortSighted)
  evalFeatures(formula, data, estimators)
}

evalRegrFeatures <- function (formula, data)
{
  estimators <- list("MSEofMean", "RReliefFexpRank")
  evalFeatures(formula, data, estimators)
}
```


Poglejmo si vse ocene za trenutno mnozico atributov:

```{R}
evalClassFeatures(namembnost ~ ., train)
```

```{R}
evalRegrFeatures(poraba ~ ., train)
```

Poskusimo izboljsati prvotno podatkovno mnozico z dodajanjem / odstranjevanjem atributov.
```{R}
classSetBase <- list(train=train, test=test)
classSetExt <- list(train=train, test=test)
classSetExt$train$datum <- NULL
classSetExt$test$datum <- NULL

summary(classSetBase$train)
summary(classSetExt$train)

regSetBase <- list(train=train, test=test)
regSetExt <- list(train=train, test=test)

ExtendRegSet <- function (set)
{
  set$letni_cas <- as.factor(ToSeason(set$datum))
  #set$mesec <- as.factor(ToMonth(set$datum))
  #set$zima <- as.factor(IsWinter(set$datum))
  #set$vikend <- as.factor(IsWeekend(set$datum))
  
  set$datum <- NULL
  set$stavba <- NULL
  set$temp_rosisca <- NULL
  set$padavine <- NULL
  set$pritisk <- NULL
  set$smer_vetra <- NULL
  set$hitrost_vetra <- NULL
  
  set$leto_izgradnje <- NULL
  set$regija <- NULL
  set$namembnost <- NULL
  set$temp_zraka <- NULL
  
  set$oblacnost <- log1p(set$oblacnost)
  set$poraba <- log1p(set$poraba)
  set$povrsina <- log1p(set$povrsina)
  
  set
}

regSetExt$train <- ExtendRegSet(regSetExt$train)
regSetExt$test <- ExtendRegSet(regSetExt$test)

summary(regSetBase$train)
summary(regSetBase$train)
```

Ponovno evaluiramo ocene atributov:
```{R}
evalClassFeatures(namembnost ~ ., classSetExt$train)
```

```{R}
evalRegrFeatures(poraba ~ ., regSetExt$train)
```


## Modeliranje

### Klasifikacija

#### Vecinski klasifikator

```{R}
# najveckrat se ponovi "izobrazevalna" namembnost
sum(test$namembnost == "izobrazevalna") / length(test$namembnost)
```

#### Odlocitveno drevo

```{R}
dtBase <- rpart(namembnost ~ pritisk, data=classSetBase$train)
EvaluateClassModel(dtBase, classSetBase$train, classSetBase$test)

dtExt <- rpart(namembnost ~ ., data=classSetExt$train)
EvaluateClassModel(dtExt, classSetExt$train, classSetExt$test)
```

#### Odlocitveno drevo z rezanjem

Izberemo vrednost parametra cp, ki ustreza minimalni napaki internega presnega preverjanja.
```{R}
dtBase <- rpart(namembnost ~ ., data=classSetBase$train, cp=0)
cpTab <- printcp(dtBase)
row <- which.min(cpTab[,"xerror"])
th <- mean(c(cpTab[row, "CP"], cpTab[row-1, "CP"]))
dtBase <- prune(dtBase, cp=th)
EvaluateClassModel(dtBase, classSetBase$train, classSetBase$test)

dtExt <- rpart(namembnost ~ ., data=classSetExt$train, cp=0)
cpTab <- printcp(dtExt)
row <- which.min(cpTab[,"xerror"])
th <- mean(c(cpTab[row, "CP"], cpTab[row-1, "CP"]))
dtExt <- prune(dtExt, cp=th)
EvaluateClassModel(dtExt, classSetExt$train, classSetExt$test)
```

#### Naivni Bayes

```{r}
nbBase <- CoreModel(namembnost ~ ., data=classSetBase$train, model="bayes")
EvaluateClassModel(nbBase, classSetBase$train, classSetBase$test)

nbExt <- CoreModel(namembnost ~ ., data=classSetExt$train, model="bayes")
EvaluateClassModel(nbExt, classSetExt$train, classSetExt$test)
```

#### K-bliznjih sosedov

```{R}
knnBase <- CoreModel(namembnost ~ ., data=classSetBase$train, model="knn", kInNN=5)
EvaluateClassModel(knnBase, classSetBase$train, classSetBase$test)

knnExt <- CoreModel(namembnost ~ ., data=classSetExt$train, model="knn", kInNN=5)
EvaluateClassModel(knnExt, classSetExt$train, classSetExt$test)
```


#### Nakljucni gozd

```{R}
rfBase <- randomForest(namembnost ~ ., data=classSetBase$train)
EvaluateClassModel(rfBase, classSetBase$train, classSetBase$test);

rfExt <- randomForest(namembnost ~ ., data=classSetExt$train)
EvaluateClassModel(rfExt, classSetExt$train, classSetExt$test)
```

### Regresija


#### Trivialni model

```{R}
meanValue <- mean(regSetBase$train$poraba)
predicted <- rep(meanValue, nrow(regSetBase$test))
observed <- regSetBase$test$poraba

EvaluateTrivialRegModel(observed, predicted)
```

#### Linearna regresija
```{R}
lmBase <- lm(poraba ~ ., regSetBase$train)
EvaluateRegBaseModel(lmBase, regSetBase$train, regSetBase$test)

lmExt <- lm(poraba ~ ., regSetExt$train)
EvaluateRegExtModel(lmExt, regSetExt$train, regSetExt$test)
```

#### Regresijsko drevo

```{R}
baseModel <- rpart(poraba ~ ., data=regSetBase$train)
EvaluateRegBaseModel(baseModel, regSetBase$train, regSetBase$test)

extModel <- rpart(poraba ~ ., data=regSetExt$train)
EvaluateRegExtModel(extModel, regSetExt$train, regSetExt$test)
```


#### Nakljucni gozd

```{R}
baseModel <- randomForest(poraba ~ ., data=regSetBase$train)
EvaluateRegBaseModel(baseModel, regSetBase$train, regSetBase$test)

extModel <- randomForest(poraba ~ ., data=regSetExt$train)
EvaluateRegExtModel(extModel, regSetExt$train, regSetExt$test)
```


#### Nevronske mreze

```{R}
baseModel <- nnet(poraba ~ ., regSetBase$train, size=5, decay=0.001, maxit=10000, linout=T)
EvaluateRegBaseModel(baseModel, regSetBase$train, regSetBase$test)

extModel <- nnet(poraba ~ ., regSetExt$train, size=5, decay=0.001, maxit=10000, linout=T)
EvaluateRegExtModel(extModel, regSetExt$train, regSetExt$test)
```


## Izboljsava modelov

### Klasifikacija
```{R}
runWrapper(namembnost ~ ., classSetBase$train)

dtBase <- rpart(namembnost ~ povrsina + leto_izgradnje + stavba + datum + regija + temp_zraka + temp_rosisca + oblacnost, data=classSetBase$train)
EvaluateClassModel(dtBase, classSetBase$train, classSetBase$test)
```

### Regresija
